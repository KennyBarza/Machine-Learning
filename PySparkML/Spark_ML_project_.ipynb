{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spark_ML_project_(Final).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxuQaQ0DJ0Xu"
      },
      "source": [
        "# Binary Text Classification using Spark ML in Pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeBFFA-vJ0Gw"
      },
      "source": [
        "Applying machine learning algorithms to massive datasets is challenging because most of the top machine learning algorithms are not designed for parallel architectures.\n",
        "1. Traditionally, Data scientists used python and R tools to process data on a single machine where the movement of data becomes time consuming. Here analysis requires sampling which often does not accurately represent the data, and moving from development to production environments requires extensive re-engineering.\n",
        "MLlib is Spark’s library of machine learning functions. spark.mllib contains the original API built on top of RDDs. spark.ml whereas provides a higher level API built on top of DataFrames for constructing ML pipelines and is the primary Machine Learning API for Spark at the moment.\n",
        "1. Spark stores the large datasets in cluster memory and can run the iterative algorithms without having to sync multiple times to the disk, making them run faster.\n",
        "2. Using MLlib, one can access HDFS (Hadoop Data File System) Hive and HBase, in addition to local files. This enables MLlib to be easily plugged into Hadoop workflows, so in a single platform you have it all!\n",
        "To check how it makes our life easy, let’s do a sentiment classification of Amazon fine food review dataset using Spark ML (https://www.kaggle.com/snap/amazon-fine-food-reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxzttOnvK82n"
      },
      "source": [
        "## Importing the Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3PIc1zeuu-t",
        "outputId": "eac57e8c-d3c4-4567-a40c-d732bb5c6c3c"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 70kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 37.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=2e82fa6c696779f9df23ecb2cfc62c78478d28527c1c867e1da9312987658fa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB0ncBMrumLc",
        "outputId": "2d3fb894-1c0d-43eb-c330-acb851e91c10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zX7I6KquoS7"
      },
      "source": [
        "#importing the needed libraries\n",
        "\n",
        "from pyspark.sql.types import StructType,StructField,DoubleType\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,StopWordsRemover\n",
        "import gensim\n",
        "import gensim.parsing.preprocessing as gsp\n",
        "from pyspark.sql.types import StringType\n",
        "from gensim import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REvNpXI7K6vR"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCcnVpBV0MLl",
        "outputId": "1f151016-8396-4d1a-bc79-8425eff1a5bf"
      },
      "source": [
        "#inititation of spark session\n",
        "spark = SparkSession.builder.appName(\"Final_Project\").getOrCreate()\n",
        "amazon_df = spark.read.csv(\"/content/drive/MyDrive/Amazon Food Reviews (Kaggle)/Reviews.csv\",header = True,inferSchema = True)\n",
        "amazon_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    5|1303862400|Good Quality Dog ...|I have bought sev...|\n",
            "|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    1|1346976000|   Not as Advertised|\"Product arrived ...|\n",
            "|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    4|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n",
            "|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    2|1307923200|      Cough Medicine|If you are lookin...|\n",
            "|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    5|1350777600|         Great taffy|Great taffy at a ...|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGmxWcLC6ktC"
      },
      "source": [
        "spark.catalog.clearCache()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci-dAoj20SNa",
        "outputId": "668a6174-0301-4ee1-e716-2ef4f9ab7f52"
      },
      "source": [
        "amazon_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- ProductId: string (nullable = true)\n",
            " |-- UserId: string (nullable = true)\n",
            " |-- ProfileName: string (nullable = true)\n",
            " |-- HelpfulnessNumerator: string (nullable = true)\n",
            " |-- HelpfulnessDenominator: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Time: string (nullable = true)\n",
            " |-- Summary: string (nullable = true)\n",
            " |-- Text: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64f6FWsRR-VP"
      },
      "source": [
        "We can observe the Score column in StringType, and we will need it to convert it into an Integer or float type going forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUhhAbfV0XYe",
        "outputId": "b240f012-b5df-40a3-b97d-f9e638df3d4f"
      },
      "source": [
        "amazon_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R50JHHZNLMID"
      },
      "source": [
        "Dataset consists of reviews of fine foods from amazon. Spans over a period of more than 10 years, including all ~500,000 reviews upto October 12. At the end of this study, given a review we should be able to predict whether the sentiment behind is Positive or Negative as accurately as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB20_1fL0fnU",
        "outputId": "28bbe357-b5c2-41fa-fa8b-9c41587dc28f"
      },
      "source": [
        "#The review scores given by customers have 5 different values, let's convert them to binary \n",
        "# if Score>3 --> Positive i.e 1 else Negative i.e 0\n",
        "\n",
        "def sentiment(x):\n",
        "  return 1 if str(x)>str(3) else 0\n",
        "\n",
        "# convert the return values of the funtion to integer since they are strings\n",
        "function = udf(sentiment, IntegerType())\n",
        "\n",
        "amazon_df = amazon_df.withColumn('Score', function('Score'))\n",
        "amazon_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    1|1303862400|Good Quality Dog ...|I have bought sev...|\n",
            "|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    0|1346976000|   Not as Advertised|\"Product arrived ...|\n",
            "|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    1|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n",
            "|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    0|1307923200|      Cough Medicine|If you are lookin...|\n",
            "|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    1|1350777600|         Great taffy|Great taffy at a ...|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hye-HspP0unO",
        "outputId": "2d05cbdd-1cc6-4f24-ca06-caccf809560f"
      },
      "source": [
        "amazon_df.groupBy('Score').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|Score| count|\n",
            "+-----+------+\n",
            "|    1|442001|\n",
            "|    0|126453|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E_Tjdsv02_8",
        "outputId": "7dc090ad-0fb0-4235-8ba9-64f45401f716"
      },
      "source": [
        "#checking for duplicates and dropping them\n",
        "\n",
        "if amazon_df.count() > amazon_df.dropDuplicates(['UserId','ProfileName','Time','Text']).count():\n",
        "    print ('Data has duplicates')\n",
        "print (\"Row count Now:\",amazon_df.count())\n",
        "amazon_df = amazon_df.dropDuplicates(['UserId','ProfileName','Time','Text'])\n",
        "print (\"After Removing the duplicates, row count becomes:\", amazon_df.count())\n",
        "\n",
        "\n",
        "#showing the new distribution of scores\n",
        "amazon_df.groupBy('Score').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has duplicates\n",
            "Row count Now: 568454\n",
            "After Removing the duplicates, row count becomes: 393559\n",
            "+-----+------+\n",
            "|Score| count|\n",
            "+-----+------+\n",
            "|    1|305599|\n",
            "|    0| 87960|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThlbFmp7SLEJ"
      },
      "source": [
        "Dropping unwanted columns and keeping the ID, SCORE and TEXT columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WULEc-v61E7s"
      },
      "source": [
        "cols = ('ProductId','HelpfulnessNumerator','HelpfulnessDenominator', 'UserId','Summary','ProfileName','Time')\n",
        "\n",
        "amazon_df=amazon_df.drop(*cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDAj2Ti62LAg",
        "outputId": "672dd63b-9dee-4d60-d1ac-23d71de34a1c"
      },
      "source": [
        "amazon_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+--------------------+\n",
            "| Id|Score|                Text|\n",
            "+---+-----+--------------------+\n",
            "| 32|    1|This offer is a g...|\n",
            "|282|    1|This is one of th...|\n",
            "|641|    1|I bought this tea...|\n",
            "|899|    1|The product is al...|\n",
            "|909|    1|This is my son's ...|\n",
            "+---+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CfKvVp1SPKF"
      },
      "source": [
        "Since the data consists of 300K+ rows after filtering, a lot of errors were generated when trying to tokenize and vectorize the Text column, accordingly by trial and error we kept 46255 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbUzahQpMaip"
      },
      "source": [
        "amazon_df1=amazon_df.filter(amazon_df.Id <= 50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEo0DxvHMeWO",
        "outputId": "86bce158-c1b1-419d-a5aa-ae39e1e4393c"
      },
      "source": [
        "amazon_df1.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwELkiBCS5E5"
      },
      "source": [
        "The next step is to start the tokenization process and remove stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8BUyqBr2U-V"
      },
      "source": [
        "tokenization=Tokenizer(inputCol='Text',outputCol='tokens')\n",
        "tokenized_df=tokenization.transform(amazon_df1)\n",
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
        "refined_text_df=stopword_removal.transform(tokenized_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XqIt25TS_2l"
      },
      "source": [
        "Since we are now dealing with tokens only instead of an entire review, it would make sense to capture the number of tokens in each review. Accordingly, We create another column (token count) that gives the number of tokens in each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-Ugtb0K3wDi",
        "outputId": "b6055d6f-4cce-40c8-8723-b652deacaf17"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *\n",
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "refined_text_df = refined_text_df.withColumn(\"token_count\",len_udf(col('refined_tokens')))\n",
        "refined_text_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+--------------------+--------------------+--------------------+-----------+\n",
            "| Id|Score|                Text|              tokens|      refined_tokens|token_count|\n",
            "+---+-----+--------------------+--------------------+--------------------+-----------+\n",
            "| 32|    1|This offer is a g...|[this, offer, is,...|[offer, great, pr...|         11|\n",
            "|282|    1|This is one of th...|[this, is, one, o...|[one, best, tasti...|         13|\n",
            "|641|    1|I bought this tea...|[i, bought, this,...|[bought, tea, alt...|         13|\n",
            "|899|    1|The product is al...|[the, product, is...|[product, says, g...|         53|\n",
            "|909|    1|This is my son's ...|[this, is, my, so...|[son's, favorite,...|         31|\n",
            "+---+-----+--------------------+--------------------+--------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49DawSlTQDg"
      },
      "source": [
        "Now that we have the refined tokens after stopword removal,  we use a countvectorizer for feature vectorization for the Machine Learning Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCU_lZmU4h-1",
        "outputId": "85d87f86-0f2b-4503-b34e-23d2e41068e3"
      },
      "source": [
        "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_text_df=count_vec.fit(refined_text_df).transform(refined_text_df)\n",
        "cv_text_df.select(['refined_tokens','token_count','features','Score']).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+--------------------+-----+\n",
            "|      refined_tokens|token_count|            features|Score|\n",
            "+--------------------+-----------+--------------------+-----+\n",
            "|[offer, great, pr...|         11|(109985,[2,5,37,3...|    1|\n",
            "|[one, best, tasti...|         13|(109985,[4,19,26,...|    1|\n",
            "|[bought, tea, alt...|         13|(109985,[12,34,54...|    1|\n",
            "|[product, says, g...|         53|(109985,[0,1,6,10...|    1|\n",
            "|[son's, favorite,...|         31|(109985,[5,7,16,2...|    1|\n",
            "|[\"i, bought, prod...|         44|(109985,[0,1,3,10...|    1|\n",
            "|[\"i, know, super,...|         27|(109985,[4,7,10,1...|    0|\n",
            "|[love, cookies,, ...|         11|(109985,[7,30,73,...|    0|\n",
            "|[husband, diabete...|         16|(109985,[0,5,23,1...|    1|\n",
            "|[really, good., t...|         15|(109985,[11,14,22...|    1|\n",
            "+--------------------+-----------+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyUxUkux5Q7v"
      },
      "source": [
        "model_text_df=cv_text_df.select(['features','token_count','Score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k2EVHNnPXka"
      },
      "source": [
        "Once we have the feature vector for each row, we can make use of\n",
        "VectorAssembler to create input features for the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0N5AYqSPPN2",
        "outputId": "4f97f5f5-78d7-44a6-e569-cbf9d01f91e5"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "df_assembler = VectorAssembler(inputCols=['features','token_count'],outputCol='features_vec')\n",
        "model_text_df = df_assembler.transform(model_text_df)\n",
        "model_text_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- token_count: integer (nullable = true)\n",
            " |-- Score: integer (nullable = true)\n",
            " |-- features_vec: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRML3qOvPdMH"
      },
      "source": [
        "We can use any of the classification models on this data, but we\n",
        "proceed with training the Logistic Regression Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSOyzGhkPV1B"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "training_df,test_df=model_text_df.randomSplit([0.8,0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5clp0-JyPmDl"
      },
      "source": [
        "To validate the presence of enough records for both classes in the train and test dataset, we can apply the groupBy function on the Label column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzxHkvRyPjka",
        "outputId": "11c31eea-0f68-445d-ce8c-1250f520adb8"
      },
      "source": [
        "training_df.groupBy('Score').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|Score|count|\n",
            "+-----+-----+\n",
            "|    1|28346|\n",
            "|    0| 8734|\n",
            "+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aAoPH_bPot6",
        "outputId": "61072065-f108-401d-8f46-e92ebb52f3c0"
      },
      "source": [
        "test_df.groupBy('Score').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|Score|count|\n",
            "+-----+-----+\n",
            "|    1| 7029|\n",
            "|    0| 2146|\n",
            "+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9C43XKhPxUv"
      },
      "source": [
        "#fit our model on the training set\n",
        "\n",
        "log_reg=LogisticRegression(featuresCol='features_vec',labelCol='Score').fit(training_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xLQZSNOP4f-"
      },
      "source": [
        "After training the model, we evaluate the performance of the model on\n",
        "the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjxGe9ilP3r7",
        "outputId": "cb315a4b-521e-4059-8f5e-a6682265b68d"
      },
      "source": [
        "results=log_reg.evaluate(test_df).predictions\n",
        "results.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|            features|token_count|Score|        features_vec|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|(109985,[0,1,2,3,...|        162|    1|(109986,[0,1,2,3,...|[-808.96930895599...|           [0.0,1.0]|       1.0|\n",
            "|(109985,[0,1,2,13...|         38|    0|(109986,[0,1,2,13...|[124.898249192134...|           [1.0,0.0]|       0.0|\n",
            "|(109985,[0,1,3,5,...|         40|    1|(109986,[0,1,3,5,...|[-369.97989620157...|[2.08820275557210...|       1.0|\n",
            "|(109985,[0,1,3,6,...|         21|    0|(109986,[0,1,3,6,...|[111.969117973450...|           [1.0,0.0]|       0.0|\n",
            "|(109985,[0,1,3,10...|         44|    1|(109986,[0,1,3,10...|[-80.102113705153...|[1.62964882958989...|       1.0|\n",
            "|(109985,[0,1,5,6,...|         18|    1|(109986,[0,1,5,6,...|[32.1010915639252...|[0.99999999999998...|       0.0|\n",
            "|(109985,[0,2,7,14...|         47|    1|(109986,[0,2,7,14...|[-43.588596719273...|[1.17412131123511...|       1.0|\n",
            "|(109985,[0,2,7,15...|         55|    1|(109986,[0,2,7,15...|[-245.66730530101...|[2.03256725024345...|       1.0|\n",
            "|(109985,[0,2,15,5...|         29|    1|(109986,[0,2,15,5...|[18.2416333493333...|[0.99999998803922...|       0.0|\n",
            "|(109985,[0,3,4,8,...|         21|    1|(109986,[0,3,4,8,...|[-252.07351309942...|[3.35632669333922...|       1.0|\n",
            "|(109985,[0,3,11,4...|         24|    1|(109986,[0,3,11,4...|[-107.12967441187...|[2.97970695622934...|       1.0|\n",
            "|(109985,[0,4,5,15...|         16|    1|(109986,[0,4,5,15...|[-35.319019463655...|[4.58294600672020...|       1.0|\n",
            "|(109985,[0,4,21,2...|         21|    0|(109986,[0,4,21,2...|[-29.329666112930...|[1.82931228557841...|       1.0|\n",
            "|(109985,[0,5,7,16...|         26|    1|(109986,[0,5,7,16...|[-57.654670327582...|[9.13891884579219...|       1.0|\n",
            "|(109985,[0,6,18,5...|         34|    0|(109986,[0,6,18,5...|[35.5607286089972...|[0.99999999999999...|       0.0|\n",
            "|(109985,[0,8,15,1...|         16|    0|(109986,[0,8,15,1...|[-178.75495665682...|[2.33189349585621...|       1.0|\n",
            "|(109985,[0,10,17,...|         51|    1|(109986,[0,10,17,...|[-98.411495093877...|[1.82150649803075...|       1.0|\n",
            "|(109985,[0,18,30,...|        111|    1|(109986,[0,18,30,...|[536.870064586211...|           [1.0,0.0]|       0.0|\n",
            "|(109985,[0,18,47,...|         19|    0|(109986,[0,18,47,...|[-170.20689334121...|[1.20250098285487...|       1.0|\n",
            "|(109985,[0,36,58,...|         25|    1|(109986,[0,36,58,...|[49.5674443176294...|           [1.0,0.0]|       0.0|\n",
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eLT7VRlQEui"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYZcsC8TQHBr"
      },
      "source": [
        "true_postives = results[(results.Score == 1) & (results.prediction == 1)].count()\n",
        "true_negatives = results[(results.Score == 0) & (results.prediction == 0)].count()\n",
        "false_positives = results[(results.Score == 0) &(results.prediction == 1)].count()\n",
        "false_negatives = results[(results.Score == 1) & (results.prediction == 0)].count()\n",
        "recall = float(true_postives)/(true_postives + false_negatives)\n",
        "precision = float(true_postives) / (true_postives +false_positives)\n",
        "accuracy=float((true_postives+true_negatives) /(results.count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZAlp-ePQkwt",
        "outputId": "407e114e-29a9-4e48-cd8f-f20586eb0c9a"
      },
      "source": [
        "print(true_postives)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hch4mItv6ktM",
        "outputId": "d84bdc4e-5ceb-4514-d3c8-778668e7b52d"
      },
      "source": [
        "print(true_negatives)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uoMPBaO6ktM",
        "outputId": "664fe16e-54ad-4955-eaa0-6c15d8f83238"
      },
      "source": [
        "print(false_positives)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ftra1S6ktM",
        "outputId": "b920fb66-298f-47a5-bbe6-0b05f3e9c36b"
      },
      "source": [
        "print(false_negatives)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUyypBYWQuoM",
        "outputId": "bb297b42-31f1-4c72-ded4-cc1a2b42ffdb"
      },
      "source": [
        "print(recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8520415421823873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a8kY1bIQzEO",
        "outputId": "9d41ff56-a04a-4a59-f9e7-6ca038db975e"
      },
      "source": [
        "print(precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.868600435097897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXD0ReI6REEV",
        "outputId": "abfed985-7923-4998-d335-760d6629cf47"
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7879019073569482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsUrxWV7vuO0"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qljqiAMVL4c5"
      },
      "source": [
        "For the TF-IDF featurization we decided to reduce further the number of rows due to the large amount of errors generated. The final dataset consisted of 19310 rows.\n",
        "The idea behind TF-IDF scheme is the fact that words having a high frequency of occurrence in one document, and less frequency of occurrence in all the other documents, are more crucial for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F4QNYZx6ktO"
      },
      "source": [
        "amazon_df2=amazon_df.filter(amazon_df.Id <= 20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PSkC_G66ktO",
        "outputId": "7da1393a-12dc-4b69-8c1a-ca02d2c75cfd"
      },
      "source": [
        "amazon_df2.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19310"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzoar-RN6ktO",
        "outputId": "ff999c58-55ac-49f6-8736-9e69656d07d4"
      },
      "source": [
        "amazon_df2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+--------------------+\n",
            "| Id|Score|                Text|\n",
            "+---+-----+--------------------+\n",
            "| 32|    1|This offer is a g...|\n",
            "|282|    1|This is one of th...|\n",
            "|641|    1|I bought this tea...|\n",
            "|899|    1|The product is al...|\n",
            "|909|    1|This is my son's ...|\n",
            "+---+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6GZMWeR6ktP"
      },
      "source": [
        "#splitting the data 80% for train and 20% for test\n",
        "train_df, test_df = amazon_df2.randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbhAlQdH6ktP",
        "outputId": "cc546813-c288-4379-d88d-369c43405301"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(),outputCol=\"rawFeatures\")\n",
        "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\",minDocFreq=5)\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
        "\n",
        "# Fit the pipeline to training documents.\n",
        "model1 = pipeline.fit(train_df)\n",
        "\n",
        "train_df = model1.transform(train_df)\n",
        "test_df = model1.transform(test_df)\n",
        "\n",
        "print (\"few rows from test df\")\n",
        "test_df.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "few rows from test df\n",
            "+----+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|  Id|Score|                Text|               words|         rawFeatures|            features|\n",
            "+----+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|1019|    1|\"I bought this pr...|[\"i, bought, this...|(262144,[7391,190...|(262144,[7391,190...|\n",
            "|2369|    0|I love these cook...|[i, love, these, ...|(262144,[19036,22...|(262144,[19036,22...|\n",
            "|7053|    1|this filters are ...|[this, filters, a...|(262144,[19036,27...|(262144,[19036,27...|\n",
            "+----+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXwEvvBFMhsP"
      },
      "source": [
        "Using Logistic Regression as our classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neTRnyWU6ktP",
        "outputId": "9a4f78b2-8219-4d91-a5ec-eef08c0449a3"
      },
      "source": [
        "def logistic_reg(train_data, test_data):\n",
        "    # Create initial Logistic regression model\n",
        "    \n",
        "    lr = LogisticRegression(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    model = lr.fit(train_data)\n",
        "    predictions = model.transform(test_data)\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print (\"Accuracy of Logistic Regression Classifier : %g\" % accuracy)\n",
        "\n",
        "logistic_reg(train_df, test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression Classifier : 0.813048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzZXdNK4MpmP"
      },
      "source": [
        "We can see that the accuracy is not great but not bad either. Let’s try some hyper-parameter tuning on our classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Qm6PZS6ktQ",
        "outputId": "b2afea4a-7c63-4f14-8c52-4de979387f84"
      },
      "source": [
        "def logisticCV(train_df,test_df):\n",
        "    lr = LogisticRegression(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    pipeline = Pipeline(stages= [lr])\n",
        "    paramGrid = (ParamGridBuilder()\n",
        "                     .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
        "                     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "                     .addGrid(lr.maxIter, [1, 5, 10])\n",
        "                     .build())\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    crossValidator = CrossValidator(estimator=pipeline,\n",
        "                                        evaluator=evaluator,\n",
        "                                        estimatorParamMaps=paramGrid,\n",
        "                                        numFolds=5)\n",
        "    # use the Logistic Regression Classifier to train (fit) the model\n",
        "    # and Get the best Logistic Regression model\n",
        "\n",
        "    cv = crossValidator.fit(train_df)\n",
        "    best_model = cv.bestModel.stages[0]\n",
        "\n",
        "    prediction = best_model.transform(test_df)\n",
        "    acc = evaluator.evaluate(prediction)\n",
        "    print (\"The test's accuracy with cross validation = %g\" % acc)   \n",
        "logisticCV(train_df,test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test's accuracy with cross validation = 0.895345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKLPsYyIMvbf"
      },
      "source": [
        "Our accuracy improved!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLSWaItH6ktR"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zil-NDG9NPrr"
      },
      "source": [
        "Let's try now the word2vec featurization and let’s see if there is any change in the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4F0B5dd6ktS",
        "outputId": "ad51159d-e60b-4009-8dd5-4f94a98a8d46"
      },
      "source": [
        "from pyspark.ml.feature import Word2Vec\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"Text\",outputCol=\"words\")\n",
        "w2v = Word2Vec(vectorSize=300, minCount=0, inputCol=\"words\", outputCol=\"features\")\n",
        "doc2vec_pipeline = Pipeline(stages=[tokenizer,w2v])\n",
        "doc2vec_model = doc2vec_pipeline.fit(train_df)\n",
        "train_df = doc2vec_model.transform(train_df)\n",
        "test_df = doc2vec_model.transform(test_df)\n",
        "print (\"few rows from train df\")\n",
        "train_df.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "few rows from train df\n",
            "+---+-----+--------------------+--------------------+--------------------+\n",
            "| Id|Score|                Text|               words|            features|\n",
            "+---+-----+--------------------+--------------------+--------------------+\n",
            "| 32|    1|This offer is a g...|[this, offer, is,...|[0.03636288617174...|\n",
            "|282|    1|This is one of th...|[this, is, one, o...|[-0.0149411184258...|\n",
            "|641|    1|I bought this tea...|[i, bought, this,...|[-0.0097574412660...|\n",
            "+---+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY2CdBkQ6ktS",
        "outputId": "dc47833c-50a4-4640-f436-c74ade3fe16f"
      },
      "source": [
        "def logistic_reg(train_data, test_data):\n",
        "    # Create initial Logistic regression model\n",
        "    \n",
        "    lr = LogisticRegression(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    model = lr.fit(train_data)\n",
        "    predictions = model.transform(test_data)\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print (\"Accuracy of Logistic Regression Classifier : %g\" % accuracy)\n",
        "    \n",
        "logistic_reg(train_df, test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression Classifier : 0.828797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Hak9op6ktT",
        "outputId": "64d3f17a-e07e-4e31-cf51-758bfe82b0d3"
      },
      "source": [
        "def logisticCV(train_df,test_df):\n",
        "    lr = LogisticRegression(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    pipeline = Pipeline(stages= [lr])\n",
        "    paramGrid = (ParamGridBuilder()\n",
        "                     .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
        "                     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "                     .addGrid(lr.maxIter, [1, 5, 10])\n",
        "                     .build())\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    crossValidator = CrossValidator(estimator=pipeline,\n",
        "                                        evaluator=evaluator,\n",
        "                                        estimatorParamMaps=paramGrid,\n",
        "                                        numFolds=5)\n",
        "    # use the Logistic Regression Classifier to train (fit) the model\n",
        "    # and Get the best Logistic Regression model\n",
        "\n",
        "    cv = crossValidator.fit(train_df)\n",
        "    best_model = cv.bestModel.stages[0]\n",
        "\n",
        "    prediction = best_model.transform(test_df)\n",
        "    acc = evaluator.evaluate(prediction)\n",
        "    print (\"The test's accuracy with cross validation = %g\" % acc)  \n",
        "logisticCV(train_df,test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test's accuracy with cross validation = 0.811879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wenmbGGu6ktT",
        "outputId": "0c162b18-c4ef-4fdb-aab8-5f85c9a71aff"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "def RandomForest(train_df,test_df):\n",
        "    rf = RandomForestClassifier(labelCol=\"Score\", featuresCol=\"features\")\n",
        "    model = rf.fit(train_df)\n",
        "    predictions = model.transform(test_df)\n",
        "    evaluator = BinaryClassificationEvaluator(labelCol=\"Score\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print (\"Accuracy of Random Forest Classifierr : %g\" % accuracy)\n",
        "RandomForest(train_df,test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forest Classifierr : 0.77072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25s8jYPx6ktW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}